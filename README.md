# Journals Scraper

<!-- insertar logo que se encuentra en /images/img1 en una escala del 50%.jpg  -->

![logo](images/img2.jpg) 


## Table of Contents

- [Journals Scraper](#journals-scraper)
  - [Table of Contents](#table-of-contents)
  - [Description](#description)
  - [Features](#features)
  - [Installation](#installation)
  - [Usage](#usage)
  - [Content structure](#content-structure)
  - [Contributing](#contributing)
  - [License](#license)
  - [Contact](#contact)


## Description

A project for scraping free journals available on the internet.

This project aims to scrape and collect data from various websites that provide free access to journals. 
Collected documents can be used for various purposes such as research, analysis, or building a database of scholarly articles, but most for reading.

## Features

- Web scraping to collect journal data
- Data processing and cleaning
- Storage and retrieval of scraped data
- Documentation and reporting

## Installation

1. Clone the repository: `git clone https://github.com/vjvelascorios/Journals-Scrapper.git`
2. Install the required dependencies: `pip install -r requirements.txt`

## Usage

1. Configure the scraping parameters in the `config.py` file.
2. Run the main script: `python main.py`
3. The scraped data will be stored in the specified output directory.

## Content structure

ðŸ“¦Journals Scraping
 â”£ ðŸ“‚code
 â”£ ðŸ“‚contents
 â”ƒ â”£ ðŸ“‚en
 â”ƒ â”— ðŸ“‚es
 â”£ ðŸ“‚doc
 â”£ ðŸ“‚images
 â”ƒ â”£ ðŸ“œimg1.jpg
 â”ƒ â”£ ðŸ“œimg2.jpg
 â”ƒ â”— ðŸ“œimg3.jpg
 â”£ ðŸ“œREADME
 â”— ðŸ“œrequirements.txt


## Contributing

Contributions are welcome! If you have any ideas, suggestions, or bug reports, please open an issue or submit a pull request.

## License

This project is licensed under the [MIT License](LICENSE).

## Contact

For any questions or inquiries, please contact [vj.velascorios@gmail.com](mailto:vj.velascorios@gmail.com).